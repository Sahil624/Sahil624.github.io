{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40233b82-23a8-464e-b147-3fbebb0a82cf",
   "metadata": {},
   "source": [
    "# MNIST Digit Classification using PyTorch\n",
    "\n",
    "This project implements a **very basic neural network** to classify handwritten digits from the MNIST dataset using PyTorch. The model achieves 95% accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "517dcaa1-53bb-4c3e-9399-db3e78f5c579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbc8a393-8915-4791-a70c-47ff4e3ddea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will be using: cuda\n"
     ]
    }
   ],
   "source": [
    "# Setup device agnostic code\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Will be using:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dddb429-6f53-40c9-9026-87e80c20e28a",
   "metadata": {},
   "source": [
    "## Dataset Overview\n",
    "\n",
    "MNIST is like the \"Hello World\" of machine learning. It's a dataset of 70,000 handwritten digits that has been used to train and test machine learning models for decades. Each image is a 28×28 pixel grayscale picture of a single digit from 0 to 9.\n",
    "\n",
    "The dataset includes:\n",
    "- 60,000 training images\n",
    "- 10,000 test images\n",
    "- 28×28 pixel resolution\n",
    "- Grayscale format\n",
    "- 10 possible classes (digits 0-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17a79c79-63a9-4c1d-ab9e-c241a0be5e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Sample torch.Size([1, 28, 28]) 5 60000\n",
      "Test Sample torch.Size([1, 28, 28]) 7 10000\n"
     ]
    }
   ],
   "source": [
    "transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "print(\"Train Sample\", train_dataset[0][0].shape, train_dataset[0][1], len(train_dataset))\n",
    "print(\"Test Sample\", test_dataset[0][0].shape, test_dataset[0][1], len(test_dataset))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1028, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1028, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e108e1c7-a974-4cac-a2c4-54eb6ced9a14",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "Hidden Units = 25\n",
    "\n",
    "Why 25 neurons? It's a sweet spot I found through experimentation:\n",
    "\n",
    "- Too few neurons (like 10) → The model struggles to learn patterns\n",
    "- Too many neurons (like 100) → Takes longer to train and might memorize instead of learn\n",
    "- 25 neurons → Just right for recognizing digit patterns!\n",
    "---\n",
    "\n",
    "For this project, I've designed a simple yet effective neural network with three layers. Think of it as a pipeline that processes the image through different stages:\n",
    "\n",
    "1. **Input Layer**: \n",
    "   - Takes our flattened 28×28 image (784 pixels)\n",
    "   - Each pixel becomes an input neuron\n",
    "\n",
    "2. **Hidden Layers**: \n",
    "   - Two layers with 25 neurons each\n",
    "   - ReLU activation for introducing non-linearity\n",
    "   - These layers learn to recognize different features of the digits\n",
    "\n",
    "3. **Output Layer**:\n",
    "   - 10 neurons (one for each digit)\n",
    "   - Gives us probabilities for each possible digit\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1338ee04-a13c-4b5f-90ff-75aa8e3bfc63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MnistModal(\n",
       "  (layer_1): Linear(in_features=784, out_features=25, bias=True)\n",
       "  (layer_2): Linear(in_features=25, out_features=25, bias=True)\n",
       "  (layer_3): Linear(in_features=25, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MnistModal(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        in_features = 784\n",
    "        hidden_units = 25\n",
    "        out_features = 10\n",
    "\n",
    "        self.layer_1 = nn.Linear(in_features=in_features, out_features=hidden_units)\n",
    "        self.layer_2 = nn.Linear(in_features=hidden_units, out_features=hidden_units)\n",
    "        self.layer_3 = nn.Linear(in_features=hidden_units, out_features=out_features)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 784)\n",
    "        x = self.layer_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer_3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model_0 = MnistModal().to(device)\n",
    "\n",
    "model_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e7c9fa-9910-4880-a397-ddaecd3b64f1",
   "metadata": {},
   "source": [
    "## The Training Setup\n",
    "\n",
    "### Loss Function: CrossEntropyLoss\n",
    "Think of this as our AI's \"grading system\":\n",
    "- Perfect for classification tasks (like our digit recognition)\n",
    "- Combines softmax activation and negative log-likelihood\n",
    "- Helps the model understand how badly it messed up each guess\n",
    "\n",
    "### Optimizer: Adam\n",
    "- Learning rate = 0.02 (how big steps we take while learning)\n",
    "- Why Adam?\n",
    "    - Adapts the learning rate automatically\n",
    "    - Generally works better than basic SGD\n",
    "    - Handles different parameters at different scales well\n",
    "\n",
    "### Accuracy Metric: MulticlassAccuracy\n",
    "Our \"report card\":\n",
    "- Straightforward: number of correct predictions ÷ total predictions\n",
    "- Perfect for our 10-class problem\n",
    "- Gives us a clear percentage we can understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3327752-a55b-422e-a9ec-2f81072f113f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MulticlassAccuracy()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_0.parameters(), lr=0.02)\n",
    "\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "acc_fn = Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
    "acc_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a584d27c-82f2-4a1b-ae41-5ace996d9fb3",
   "metadata": {},
   "source": [
    "## Untrained Model Prediction\n",
    "\n",
    "Let's start with a fun experiment! Before training our model, let's see how it performs on some sample data. Think of this like asking a toddler to read numbers before teaching them - the results should be interesting! \n",
    "\n",
    "Looking at our results:\n",
    "- Accuracy: 13.33%\n",
    "- Loss: 2.29\n",
    "- Model mostly predicted 4, 5, and 8\n",
    "\n",
    "This is exactly what we expected! Without any training, our model is just making random guesses. The 13.33% accuracy is actually close to random chance (10% for 10 digits). The high loss value (2.29) indicates how uncertain and incorrect these predictions are.\n",
    "\n",
    "This gives us a great baseline to compare against after training. It's like taking a \"before\" picture in a fitness journey - it'll make our progress much more apparent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c649d664-4b4c-42b5-a3c2-90ea7fd58b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred labels: tensor([8, 5, 5, 4, 5, 4, 5, 5, 5, 4, 5, 4, 5, 5, 5, 5, 8, 5, 8, 5, 5, 5, 5, 5,\n",
      "        4, 5, 8, 5, 4, 5], device='cuda:0')\n",
      "Tarin labels: tensor([3, 9, 4, 3, 2, 0, 7, 7, 2, 1, 4, 0, 1, 5, 1, 9, 8, 0, 7, 6, 1, 5, 8, 4,\n",
      "        8, 2, 8, 9, 9, 4], device='cuda:0')\n",
      "Accuracy: tensor(0.1333, device='cuda:0')\n",
      "Loss: tensor(2.2932, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_loader))\n",
    "train_features, train_labels = train_features.to(device), train_labels.to(device)\n",
    "\n",
    "sample_size = 30\n",
    "\n",
    "y_logits = model_0(train_features[:sample_size])\n",
    "# print(\"Logits:\", y_logits.squeeze())\n",
    "\n",
    "y_pred_probs = torch.softmax(y_logits, dim=1)\n",
    "# print(\"Pred probs:\", y_pred_probs.squeeze())\n",
    "\n",
    "_, y_preds = torch.max(y_pred_probs, 1)\n",
    "#y_preds = y_pred_probs.argmax(dim=1)\n",
    "print(\"Pred labels:\", y_preds)\n",
    "print(\"Tarin labels:\", train_labels[:sample_size])\n",
    "\n",
    "accuracy = acc_fn(y_preds, train_labels[:sample_size])\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "loss = loss_fn(y_logits, train_labels[:sample_size])\n",
    "print(\"Loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2e2afda-b200-4625-b405-374818236711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Loss: 0.13 Acc: 0.96 | Test loss: 0.15 Test acc: 0.96\n",
      "Epoch: 20 | Loss: 0.08 Acc: 0.97 | Test loss: 0.20 Test acc: 0.95\n",
      "Epoch: 30 | Loss: 0.08 Acc: 0.97 | Test loss: 0.27 Test acc: 0.95\n",
      "Epoch: 40 | Loss: 0.07 Acc: 0.98 | Test loss: 0.19 Test acc: 0.97\n",
      "Epoch: 50 | Loss: 0.11 Acc: 0.97 | Test loss: 0.26 Test acc: 0.95\n",
      "Epoch: 60 | Loss: 0.02 Acc: 0.99 | Test loss: 0.33 Test acc: 0.95\n",
      "Epoch: 70 | Loss: 0.06 Acc: 0.99 | Test loss: 0.33 Test acc: 0.95\n",
      "Epoch: 80 | Loss: 0.04 Acc: 0.99 | Test loss: 0.39 Test acc: 0.94\n",
      "Epoch: 90 | Loss: 0.04 Acc: 0.99 | Test loss: 0.38 Test acc: 0.95\n",
      "Epoch: 100 | Loss: 0.06 Acc: 0.98 | Test loss: 0.26 Test acc: 0.95\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    model_0.train()\n",
    "\n",
    "    for train_features, train_labels in train_loader:\n",
    "        train_features, train_labels = train_features.to(device), train_labels.to(device)\n",
    "\n",
    "        y_logits = model_0(train_features)\n",
    "        y_pred_probs = torch.softmax(y_logits, dim=1)\n",
    "        _, y_preds = torch.max(y_pred_probs, 1)\n",
    "        \n",
    "        acc = acc_fn(y_preds, train_labels)\n",
    "        loss = loss_fn(y_logits, train_labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        model_0.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for test_featues, test_labels in test_loader:\n",
    "            test_featues, test_labels = test_featues.to(device), test_labels.to(device)\n",
    "            \n",
    "            test_logits = model_0(test_featues)\n",
    "            test_pred_probs = torch.softmax(test_logits, dim=1)\n",
    "            _, test_preds = torch.max(test_pred_probs, 1)\n",
    "            \n",
    "            test_acc = acc_fn(test_preds, test_labels)\n",
    "            test_loss = loss_fn(test_logits, test_labels)\n",
    "    \n",
    "    # Print out what's happening every 10 epochs\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch} | Loss: {loss:.2f} Acc: {acc:.2f} | Test loss: {test_loss:.2f} Test acc: {test_acc:.2f}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9512ab4a-5201-4e6d-9222-9f30cbdc7deb",
   "metadata": {},
   "source": [
    "## Results: How Well Did We Do?\n",
    "After all that training, our model achieved:\n",
    "- Training Accuracy: 98% (how well it knows the training data)\n",
    "- Test Accuracy: 95% (how well it handles new numbers)\n",
    "- Training Time: ~5 minutes on RTX 2080\n",
    "\n",
    "This means our AI can correctly identify 95 out of 100 new handwritten digits it's never seen before! Pretty impressive for a simple network, right?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5c98ba-01fe-4865-86c2-fbb55d959b9e",
   "metadata": {},
   "source": [
    "## Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8a4c802-32e9-41f9-833e-2fc1be5c3c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzgAAAI5CAYAAABtp5+TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAAsTAAALEwEAmpwYAAAt2klEQVR4nO3de5idZXkv4N9HgAQaT4CRgoJQQCXISQuRclA5tJuIotDd1KJsrbu2UNlQPFQQh+WhWmypRTyCilgQld2qkS0inrFaVBQqVdhY8RCQg4GEyEmSb/8xk+5par53hVmzZtab+74urouZ58n7PQtYL+u3vpn1Nm3bBgAAoAabzPQAAAAAgyLgAAAA1RBwAACAagg4AABANQQcAACgGgIOAABQDQGH/9D0mguaXvOmmZ4DqJ/9Bhgme87GZdOZHoAN0/Sam5M8LsnqJL9M8pkkf96OtatmYJYXJnlLkm2SfC7JS9uxdvmw5wCmx2zabybN9IEkL0myazvW3jRTcwCDN1v2nKbXLE7y2iR7JLk/yaeTnNKOtfcMcw4ePndwRtNR7Vg7P8m+SZ6e5HXrNjS9ZlrDa9NrFiZ5b5IXZXwzujfJu6bzmsCMmPH9ZtJ1DkzyW8O4FjBjZsOe86gkb0qyXZKnJNk+ydum+ZoMkDs4I6wda5c1veYzGX+HIU2vaZP8eZKTM/7vdqem1zwn40/SJyb5tyR/2o61103075Pk/Ul2TfJ/krQbcPk/SrK0HWu/MrHWGUm+3/SaR3iHA+ozw/vN2hc070hyfJJrp/6IgNlsJvecdqy9eNKX9za95rwkvSk+JIbIHZwR1vSaJyQ5Msl3Jn376CT7J9l94sn9gSQvT7J1xu+4fKrpNXObXrN5kk8k+XCSrZJ8PMkx66x/98Q7pr/Owkx6kdGOtT9M8mCS3ab8wIBZZ4b3myQ5JclX1r54Aeo2C/acyQ5Ocv3DfjAMnTs4o+kTTa95KMmKJJcl+atJtbes/T2Yptf8SZL3tmPtv0zUPtT0mtOSLMr4OxmbJXl7O9a2SS5tes1fTL5IO9Y+umOG+RPXn2xFkkc8vIcEzFIzvt9MvNB5eZKnDeYhAbPYjO85kzW95vCM3zne/+E/JIZNwBlNR7dj7ZXrqf100t/vmOT4pte8YtL3Ns/4z5S2SZZNPPHX+vEGzLAqySPX+d4jk/jxNKjLbNhv3p7kDe1Yu+6bKkB9ZsOekyRpes2iJBcnObYda2/c0D/PzBFw6jP5yfzTJG9ux9o3r9vU9JpDkmzf9Jpm0gawQ5If9nmd65PsNWm9nZPMTWIDgI3HsPabQ5Mc2PSasyZ97+tNr/lf6/ysPFC3Ye05a3+H51MZ/4TYz09hZmaAgFO385L8U9NrrkxydZItkzwzyVeSfD3JQ0lOanrNu5IclWS/JF/sc+2LMv4C46Ak1yR5Q5J/9AEDsNGazv1mt/zn3xm9dWINHzYAG69p23OaXrNHksuTvKIda5cOfnSmmw8ZqFg71n4ryf9Mcm6Su5LclOR/TNQeTPKCia+XJ/mDJP84+c83vWbVRID5dWtfn+RPMx50bs/4796cMA0PAxgB07zf3N6OtT9f+9fEt+9sx9r7puGhACNgOvecJKcmeWyS90/0rWp6jQ8ZGCFN+59+PBEAAGB0uYMDAABUQ8ABAACqIeAAAADVEHAAAIBqCDgAAEA1nIMzQppes2rSl1smeSDJ6omvX96OtRcNcZYXJnlLkm2SfC7jB2EtH9b1gek3m/acSTN9IMlLkuzajrU3Dfv6wPSYLftN02sWJ3ltkj2S3J/k00lOcc7faBFwRkg71s5f+/dNr7k5ycvasfbKdfuaXrNpO9Y+NF1zNL1mYZL3Jlmc8UM+35fkXUmWTNc1geGbLXvOpOscmOS3pvs6wPDNov3mUUnelPEDQ+cmuTjJ2zJ+9h8jQsCpQNNrnpnkH5K8I8kpST7X9JrPZ3xzOHBSX5uJdz2bXjM3yZuT/PeMP4H/KePvUPRzcN4fJVnajrVfmVj3jCTfb3rNI7zDAfWbgT0nTa/ZdOJ6xye5dnCPBpjNhr3ftGPtxZO+vLfpNecl6Q3o4TAkfgenHtsm2SrJjkn+pI/+tybZLcneSXZJsn2S168tNr3m7ol3S3+dhZn0AqMda3+Y5MGJ9YCNwzD3nGT8hc1X2rH2uoc7MDCyhr3fTHZwkus3ZFhmnjs49ViTZKwdax9IkqbXrLex6TVNxjeIPdf+3kzTa/4q47dhX5sk7Vj76I5rzU+yYp3vrUjyiIc5OzB6hrbnNL3mCUlenuRpA5odGC3DfI0zea3DM37XeP8pzM4MEHDqcUc71t7fZ+9jM/4LfN+etEk0Seb0+edXJXnkOt97ZBI/ngYbj2HuOW9P8oZ2rF33jRVg4zDM/Wb8D/SaRRkPRce2Y+2NG/JnmXkCTj3adb7+Zcaf4EmSptdsO6l2Z5L7kixsx9plD+Na1yfZa9LaO2f8Z1xtALDxGOaec2iSA5tec9ak73296TX/a52flwfqNMz9Jk2v2SfJpzL+CbGffzhrMLP8Dk69rk2ysOk1eze9Zl6SM9cW2rF2TZLzkvxd02sWJEnTa7Zves3v9rn2RUmOanrNQU2v+Y0kb0jyjz5gADZq07nn7JbxN1X2nvgrSY7K+C8OAxufadtvml6zR5LLk7yiHWuXDnxyhkLAqdTE7dQ3JLkyyf9NctU6La9JclOSbzS9ZuVE35PWFptes6rpNQetZ+3rM/5xiRcluT3jv3tzwqAfAzA6pnnPub0da3++9q+Jb9/Z7yewAXWZzv0myakZ/zG390/0rWp6jQ8ZGDFN26571w8AAGA0uYMDAABUQ8ABAACqIeAAAADVEHAAAIBqCDgAAEA1Og/6bJrGR6zBiGvbtil3zQ72HBh9o7Ln2G9g9K1vv3EHBwAAqIaAAwAAVEPAAQAAqiHgAAAA1RBwAACAagg4AABANQQcAACgGgIOAABQDQEHAACohoADAABUQ8ABAACqIeAAAADVEHAAAIBqCDgAAEA1BBwAAKAam870AAAAMNlv/dZvddYPPvjggVznyCOP7KwvXbq0uMaFF144kFkYHHdwAACAagg4AABANQQcAACgGgIOAABQDQEHAACohoADAABUQ8ABAACqIeAAAADVcNAnAACzyn777ddZP//884cyx1FHHVXsWb58ebHn5ptv7qx/73vf63ck+uAODgAAUA0BBwAAqIaAAwAAVEPAAQAAqiHgAAAA1RBwAACAagg4AABANQQcAACgGk3btusvNs36i1ThrLPOKva86lWv6qx3/Te01vXXX1/sed7zntdZ//d///fiGvxXbds2Mz1Dv4a155xyyinFnhe96EWd9X6eO5dccknfM0EtRmXP8RpndluwYEFnvZ99/LLLLpvyHJtttlmx54ILLij2fPOb3+ysH3fcccU17r///mLPxmZ9+407OAAAQDUEHAAAoBoCDgAAUA0BBwAAqIaAAwAAVEPAAQAAqiHgAAAA1XAOzgjbeeedO+ulczyS5LWvfW2xp5/PgB+EU089tbP+9re/fShz1GZUzqRIhrfnLF68uNhTOsNmzpw5xTXe+MY3dtbf8pa3FNeAUTMqe47XOAzKk5/85GLPt7/97c76IYccUlzjW9/6Vt8zbSycgwMAAFRPwAEAAKoh4AAAANUQcAAAgGoIOAAAQDUEHAAAoBoCDgAAUA0BBwAAqIaDPkfYZz/72c76YYcdNqRJBmPFihWd9a222mpIk9RlVA7dS2bXnvPlL3+5s/47v/M7xTVuv/32zvrTnva04hq33nprsQdmk1HZc2bTfkP9Sq9xvvCFLxTXOPbYYzvrq1ev3qCZauCgTwAAoHoCDgAAUA0BBwAAqIaAAwAAVEPAAQAAqiHgAAAA1RBwAACAajgHZ5Y65phjij2XXHJJZ32TTerKr0uXLi32vPjFL+6sr1y5clDjjIxROZMimV17zuMf//jO+uc+97niGrvuumtn/dprry2uceihhxZ77r777mIPDMuo7Dmzab+hfqVzcObPn19c4xnPeEZn/eqrr96gmWrgHBwAAKB6Ag4AAFANAQcAAKiGgAMAAFRDwAEAAKoh4AAAANUQcAAAgGoIOAAAQDU2nekB+PW22267Yk9tB3mWHHXUUcWed77znZ31E088sbjGxngYKP/Vz372s8768uXLp3yNvfbaq9jzute9rtjzyle+csqzjJJHP/rRxZ5+/tl++ctfHsA0AMw2G9crZAAAoGoCDgAAUA0BBwAAqIaAAwAAVEPAAQAAqiHgAAAA1RBwAACAagg4AABANZq2bddfbJr1F3nY+jmw8mMf+1ixZ/PNNx/EOBuVT33qU8We5z//+UOYZHjatm1meoZ+jdKes2jRomLP1772tSlfp58DfV/4whd21j/ykY9MeY5hKh10fNlllxXX2HPPPYs9z372szvrDgJ9eEZlzxml/YbRt2LFis76/Pnzi2s84xnP6KxfffXVGzRTDda337iDAwAAVEPAAQAAqiHgAAAA1RBwAACAagg4AABANQQcAACgGgIOAABQjU1neoCN0cEHH1zsmU1n3Nx///2d9aVLlxbXeNzjHlfs6eefy1Q997nPLfb89V//dbHnNa95zSDGYYRdc801xZ43v/nNnfXTTjutuMaaNWuKPe973/s66zfccENxjX4ez7DssMMOnfWnPvWpxTW6znhb69RTT+2s93OmxH333VfsAeq28847F3v6OdOMwfFPGwAAqIaAAwAAVEPAAQAAqiHgAAAA1RBwAACAagg4AABANQQcAACgGgIOAABQDQd9ToMnPOEJnfVjjjlmSJOU3XvvvcWe1772tZ31c889t7jGEUccUewZxkGf/Zg3b95Mj8AIePDBB4s95513Xme9n4M++7HFFlt01nfdddfiGtdff32xZ5999ums//znPy+ucfPNNxd7hmXx4sWd9a222qq4xrJlywY1DjAL9XNA5ymnnFLs2XLLLTvrX/3qV4tr9HNoM+PcwQEAAKoh4AAAANUQcAAAgGoIOAAAQDUEHAAAoBoCDgAAUA0BBwAAqIaAAwAAVMNBn9PghS98YWd9xx13HNIkZSeddFKx54Mf/OCUr3PTTTcVe0oHDS5cuHDKc/Rj0aJFxZ5tt922s97PgYfUb/Xq1Z31e+65p7jGIx/5yCnPcc455xR7/uiP/qjYc+SRR3bW+3meX3vttcWeq666qtgD/GelA3/7OVh45513nvIcV1xxRbHnwgsvLPa0bTvlWQZhm222KfaccMIJU77O7bffXuxZsWLFlK+zsXAHBwAAqIaAAwAAVEPAAQAAqiHgAAAA1RBwAACAagg4AABANQQcAACgGs7B2UC///u/X+zp9XpDmGQwLrvssqFcp/T5/Emy5ZZbDmGSsqc//enFntLn4jsHhyS55ZZbOutHH310cY0vfOELU55j6623LvaUzrjpx6677lrs2WWXXYo9xxxzzJRnGYTnPve5xZ53v/vdQ5iEjd2cOXOKPaXzrl760pcOapxOS5YsKfY88MADxZ6PfvSjnfVBnZNT+v/55ZdfPpDrlJTOTWPDuIMDAABUQ8ABAACqIeAAAADVEHAAAIBqCDgAAEA1BBwAAKAaAg4AAFANAQcAAKiGgz430IIFC4o9m2222RAmSe66667O+sc+9rHiGitWrBjUOJ1uuummYs/111/fWd9pp50GNQ7MCl/+8peLPV/96leLPQcddNAgxpmyTTYpv2e2Zs2aIUzSn9K8hxxySHENB30yDC9+8YuLPaWDPJctW1Zc44Mf/GCxZ+7cuZ31V73qVcU1LrroomLPPvvs01k/++yzi2vcdtttxZ6///u/76zvtddexTX6cc0113TWTzjhhIFch3Hu4AAAANUQcAAAgGoIOAAAQDUEHAAAoBoCDgAAUA0BBwAAqIaAAwAAVEPAAQAAquGgzw30N3/zNzM9wn9YsmRJZ/3KK68c0iRl/RyY95znPGcIk5R985vfLPbccccdQ5gEkk9+8pPFngMPPHDK17n33nuLPZdddllnvWma4hqLFy8u9myxxRbFnkEoHTraz6wveclLOuv9HJwIe++9d2f9rLPOKq7R6/U66/28fulnH+jneV7Sz2Ggr3zlKzvrhx9+eHGNpUuXFnuOPfbYYs8glF5blA5vZ8O4gwMAAFRDwAEAAKoh4AAAANUQcAAAgGoIOAAAQDUEHAAAoBoCDgAAUA3n4ExS+gz5JNlss82GMEly2223FXuWL18+hEkGY/fdd5/pEfr2L//yL8Wefv79wCDceuutxZ6vf/3rnfUnPvGJxTXOOOOMYs8FF1xQ7CnZd999iz2nnnpqZ/2www4rrrH11lv3PdP69HMez9lnnz3l6zgrh89//vOd9X7OtXvrW9/aWX/wwQc3aKb1adu2s97PmT277rprsefoo4/urO+1117FNfrpGZYf/OAHnfVFixYV11i1atWU55g3b16xZ+XKlZ31G2+8ccpzTDd3cAAAgGoIOAAAQDUEHAAAoBoCDgAAUA0BBwAAqIaAAwAAVEPAAQAAqiHgAAAA1Wi6Dmxqmqb7NKfKnHPOOcWeE088cQiTJB//+MeLPUuWLBnCJMkmm3Tn4D/8wz8srvGe97yn2LPlllv2PdPD9atf/arY089hW9/97ncHMM1wtG3bzPQM/drY9pxh6eewu2uvvXYIkwzG4sWLiz2f/OQniz1N0/3UKB1o2I+f/vSnxZ6ddtppyteZTUZlz5lN+03pv7Xbb7+9uMa5557bWT/yyCM3aKbp9Nu//dvFntLzszZ33XVXseeBBx6Y8nU23XTTYs/111/fWX/2s5895TkGZX37jTs4AABANQQcAACgGgIOAABQDQEHAACohoADAABUQ8ABAACqIeAAAADVEHAAAIBqlE/7qciCBQs66/vss8+QJin77Gc/O5Tr7LLLLsWe4447rrN+xhlnDGqcafeZz3ym2DNKh3hCP0bpEM9+XHfddTM9AgzU2972ts76ySefXFzjzDPPHMwwFfnJT35S7Fm1alVnvXTYeZJss802xZ6tttqqs/6YxzymuMY73/nOzvqznvWs4hqXXnppsefDH/5wsWe2cwcHAACohoADAABUQ8ABAACqIeAAAADVEHAAAIBqCDgAAEA1BBwAAKAaTdu26y82zfqLI2ivvfbqrF9zzTVDmqRs//33L/Y8+OCDnfVHP/rRxTXe8573FHue9KQnFXuG4Wc/+1mx5/LLL++sv+pVryqusXLlyr5nGgVt2zYzPUO/attzmDnPe97zij2f+MQnOutr1qyZ8hz97Fs77rjjlK8zm4zKnjNK+82SJUuKPXvvvXdn/f777y+uceCBBxZ79thjj2JPyemnn17sWb169ZSvc8UVVxR7brnlls76nDlzims89alPLfYsXLiws77ZZpsV17jssss663fccUdxjdqsb79xBwcAAKiGgAMAAFRDwAEAAKoh4AAAANUQcAAAgGoIOAAAQDUEHAAAoBoCDgAAUA0HfU4ymw76/PGPf1zsKR0Ktd122w1qnCnr58C8FStWdNaPOOKI4hqz6d/hbDEqh+4l9e05zG5nnnlmZ/11r3vdlK/Rz2GFJ554YrHn/PPPn/IswzIqe479Bkafgz4BAIDqCTgAAEA1BBwAAKAaAg4AAFANAQcAAKiGgAMAAFRDwAEAAKqx6UwPMEx33nlnZ/26664rrrHnnnsOapxOO+6441CuMyynn356seess84awiQA40pnbw3CnDlzij3z58+f9jkANibu4AAAANUQcAAAgGoIOAAAQDUEHAAAoBoCDgAAUA0BBwAAqIaAAwAAVEPAAQAAqrFRHfS5bNmyzvpFF11UXOOpT31qsadpmr5nGgW/+tWvOutvetObimu8/e1vH9A0AIOxatWqzvrq1auLa/RzkCcAw+UODgAAUA0BBwAAqIaAAwAAVEPAAQAAqiHgAAAA1RBwAACAagg4AABANQQcAACgGk3btusvNs36ixup9773vcWel73sZVO+zre+9a1iz/ve977O+tFHH11cY/vtty/2vO1tb+usf+QjHymuwcxp23ZkTp615zCbnHPOOcWeE044obN+9913F9c44ogjij3XXHNNsWe2GJU9x34Do299+407OAAAQDUEHAAAoBoCDgAAUA0BBwAAqIaAAwAAVEPAAQAAqiHgAAAA1XAODlRuVM6kSOw5UINR2XPsNzD6nIMDAABUT8ABAACqIeAAAADVEHAAAIBqCDgAAEA1BBwAAKAaAg4AAFANAQcAAKiGgAMAAFRDwAEAAKoh4AAAANUQcAAAgGoIOAAAQDUEHAAAoBoCDgAAUA0BBwAAqIaAAwAAVEPAAQAAqiHgAAAA1RBwAACAagg4AABANQQcAACgGgIOAABQDQEHAACohoADAABUQ8ABAACqIeAAAADVEHAAAIBqCDgAAEA1BBwAAKAaAg4AAFANAQcAAKiGgAMAAFRDwAEAAKrRtG070zMAAAAMhDs4AABANQQcAACgGgIOAABQDQEHAACohoADAABUQ8ABAACqIeAAAADVEHAAAIBqCDgAAEA1BBwAAKAaAg7/oek1FzS95k0zPQdQP/sNMEz2nI3LpjM9ABum6TU3J3lcktVJfpnkM0n+vB1rVw15jt9M8t4kT0/ym0l2asfam4c5AzC9ZtF+c1qS0yZ9a06SuUkWtGPtncOcBZg+s2XPmZjlFUn+IsnWSW5McnI71l417Dl4eNzBGU1HtWPt/CT7ZjxgvG7dhqbXTHd4XZPk8iTHTPN1gJk14/tNO9b+VTvWzl/7V5K/TvIl4QaqNON7TtNr9k/y1iTHJnlUkvcn+aem18yZzusyOO7gjLB2rF3W9JrPJNkjSZpe0yb58yQnZ/zf7U5Nr3lOkjcleWKSf0vyp+1Ye91E/z4Zf9LumuT/JGk34Nq3JXnXEIIUMAvM5H4zWdNrmiQvTtKbwsMBZrkZ3nOemOT6dqz99sRaFyZ5V5IFSW6d4kNjCNzBGWFNr3lCkiOTfGfSt49Osn+S3See3B9I8vKM32J9b5JPNb1mbtNrNk/yiSQfTrJVko9nnbsxTa+5u+k1B07zwwBGwCzabw7K+IuM/z2VxwPMbjO853wmyZym1+w/cdfmpUm+m+TnA3lwTDvvvo+mTzS95qEkK5JcluSvJtXe0o61y5Ok6TV/kuS97Vj7LxO1D038LPuijL+TsVmSt7djbZvk0qbX/MXki7Rj7aOn92EAI2C27TfHJ7l0Jn4mHxiK2bDn3JPxN1GuStIkuTvJf5tYixEg4Iymo9ux9sr11H466e93THL8xC/KrbV5ku0y/uRfts6T9ceDHROowKzZb5pes2WS30/yvA39s8DImA17zh8neUmShUluSnJEkk83vWafdqy9ZQPWYYYIOPWZ/GT+aZI3t2Ptm9dtanrNIUm2b3pNM2kD2CHJD4cwI1CHYe83z0+yPMmXHsaswOgb1p6zd5JPt2PtjRNfX970mluTHJDk0oc1OUMl4NTtvIx/6seVSa5OsmWSZyb5SpKvJ3koyUlNr3lXkqOS7Jfki/0u3vSaeRn/uNYkmdv0mnntWHv/4MYHRsi07jcTjk9yoR8TATK9e843k5ze9Jp3JPlRksOS7Jbke4N8AEwfHzJQsXas/VaS/5nk3CR3Zfw26/+YqD2Y5AUTXy9P8gdJ/nHyn296zaqm1xzUcYn7kqz9OfgfTHwNbISme79pes32SZ6d5MLBTw+Mmmnecy5McknG7xavTHJOkpe3Y+0PBvwwmCZN640wAACgEu7gAAAA1RBwAACAagg4AABANQQcAACgGgIOAABQDefgjJCm16ya9OWWSR5Isnri65e3Y+1FQ5rjN5O8N8nTk/xmkp3asfbmYVwbGJ5ZtOecluS0Sd+ak2RukgXtWHvnMGYAptds2W8mZnlFkr9IsnWSG5Oc3I61Vw3r+kydj4keUU2vuTnJy9qx9spfU9u0HWsfmsZrPy7JMUm+k+SfI+BA9WZyz/k11zszycHtWPvsYV0TGJ4Zfo2zf5IvJDk4yTVJ/jTJG5Js2461q7v+LLOHOzgVaHrNM5P8Q5J3JDklyeeaXvP5jG8OB07qa5Ps2o61NzW9Zm6SNyf57xl/J/SfkpzSjrXFwzrbsfa2JO9qeo3/fmAjNOw9Z51rN0lenKQ3gIcCzHIzsN88Mcn17Vj77Yl1L0zyriQLktw6oIfFNPM7OPXYNslWSXZM8id99L81yW5J9k6yS5Ltk7x+bbHpNXc3vebAX/9HAWZszzko4y80/vcGzguMrmHuN59JMqfpNfs3vWZOkpcm+W6Snz/c4Rk+78DXY02SsXasfSBJml6z3saJd0D/JMme7Vi7fOJ7f5Xk4iSvTZJ2rH30NM8LjLaZ2nOOT3JpO9auKnYCtRjmfnNPxt9AuSpJk+TuJP+tHfM7HaNEwKnHHe1Ye3+fvY/N+C/wfXvSJtFk/Bd3Afox9D2n6TVbJvn9JM/bkD8HjLxh7jd/nOQlSRYmuSnJEUk+3fSafdqx9pb+R2YmCTj1WPedhV9m/AmeJGl6zbaTancmuS/JwnasXTaE2YD6zMSe8/wky5N8aQprAKNnmPvN3kk+3Y61N058fXnTa25NckCSSx/GeswAv4NTr2uTLGx6zd5Nr5mX5My1hXasXZPkvCR/1/SaBUnS9Jrtm17zu/0uPrHm3Ikv5058DWy8pnXPmXB8kgv9qAhs9KZzv/lmksVNr9m56TVN02sOz/jv83xvoI+AaSXgVGrinYc3JLkyyf/N+M+STvaajN96/UbTa1ZO9D1pbbHpNauaXnNQxyXuS7L2Z+B/MPE1sJGa7j2n6TXbJ3l2kgsHPDowYqZ5v7kwySUZv1O8Msk5GT+H5weDfAxML+fgAAAA1XAHBwAAqIaAAwAAVEPAAQAAqiHgAAAA1eg8B6dpGp9AACOubdv1H/k8y9hzYPSNyp5jv4HRt779xh0cAACgGgIOAABQDQEHAACohoADAABUQ8ABAACqIeAAAADVEHAAAIBqCDgAAEA1BBwAAKAaAg4AAFANAQcAAKiGgAMAAFRDwAEAAKoh4AAAANUQcAAAgGoIOAAAQDUEHAAAoBoCDgAAUA0BBwAAqIaAAwAAVEPAAQAAqiHgAAAA1RBwAACAagg4AABANQQcAACgGgIOAABQDQEHAACohoADAABUQ8ABAACqIeAAAADVEHAAAIBqCDgAAEA1BBwAAKAaAg4AAFCNTWd6AEbf/vvvX+z50Ic+VOzZZ599Ouv33Xdf3zMBALBxcgcHAACohoADAABUQ8ABAACqIeAAAADVEHAAAIBqCDgAAEA1BBwAAKAazsFhKO64445ij3NuAKB+CxYsKPZ8+MMf7qzvsccexTVOPfXUYs93vvOdzvquu+5aXONzn/tcseeBBx4o9jA47uAAAADVEHAAAIBqCDgAAEA1BBwAAKAaAg4AAFANAQcAAKiGgAMAAFRDwAEAAKrhoE+m7IADDij2bLPNNsWeLbbYorPuIFD49UrPnVI9SZ7znOcUexYuXNj3TOuz//77F3tWr17dWb/mmmuKa6xZs6bvmdbn4osvLvZce+21U74O1GSTTcrvnb/61a8u9hx++OFTnqWf5/DKlSs764985COLa1x++eXFnuOOO66zvnz58uIa9M8dHAAAoBoCDgAAUA0BBwAAqIaAAwAAVEPAAQAAqiHgAAAA1RBwAACAajRt266/2DTrL8KEj3/848Webbfdtthz0EEHDWIc1tG2bTPTM/RrlPacefPmFXsOPvjgzvoOO+xQXGO//fYr9uy7775TqvPrffGLXyz2HHrooUOYZLSMyp4zSvvNKFm0aFGx55//+Z+HMMnscuKJJ3bW3/3udw9pkrqsb79xBwcAAKiGgAMAAFRDwAEAAKoh4AAAANUQcAAAgGoIOAAAQDUEHAAAoBoCDgAAUI1NZ3oAZr/ddtuts7548eLiGl//+tcHNQ7MCnvuuWex5/LLLx/CJINx//33F3v+9V//dcrXef/731/sWbJkSWf9kEMOKa7RNCNx1iSMnLlz53bWP/ShDw1ljnvuuafYc+aZZxZ7li9f3ln/y7/8y+IaT3rSk4o9z3/+8zvrDvocLHdwAACAagg4AABANQQcAACgGgIOAABQDQEHAACohoADAABUQ8ABAACqIeAAAADVcNAnRY94xCM661tssUVxjUsvvXRQ48Cs8IMf/KDYc95553XWd9hhh4HM8tBDD3XWzz777OIav/zlL4s9V199dd8zTcX73ve+zvqDDz5YXGPTTf3vDabDYYcd1ll/4hOfWFxj2bJlxZ5HPepRnfWXv/zlxTUuueSSYk/JVVddVew544wzij0veMELOuubb755cY1+9j7GuYMDAABUQ8ABAACqIeAAAADVEHAAAIBqCDgAAEA1BBwAAKAaAg4AAFANBwVQdOSRR3bWH3jggeIan/zkJwc1DswKK1euLPb0c04D/9WLXvSizrozbmDmLFmypLO+2WabFdf4wAc+UOy55pprOutLly4trjEIP/zhD4s9N9xwQ7Fn/vz5nfWmafqeiTJ3cAAAgGoIOAAAQDUEHAAAoBoCDgAAUA0BBwAAqIaAAwAAVEPAAQAAqiHgAAAA1XBa2kZul112KfacdtppnfUrrriiuMYtt9zS90zAxm2bbbaZ6RGA9dhzzz0767/61a+Ka5xzzjnFnl/84hd9zzSdnva0pxV7/viP/7jYU3o8bdv2PRNl7uAAAADVEHAAAIBqCDgAAEA1BBwAAKAaAg4AAFANAQcAAKiGgAMAAFRDwAEAAKrhoM+N3OMe97hiz9y5czvrZ5111qDGAZg1vva1r830CDBU8+bNK/b8xm/8Rmd9003LLy3PPPPMYs/555/fWb/11luLazz5yU8u9uy+++6d9ZNOOqm4xs4771zs+ehHP9pZf+ihh4pr0D93cAAAgGoIOAAAQDUEHAAAoBoCDgAAUA0BBwAAqIaAAwAAVEPAAQAAqtG0bbv+YtOsv0gV/u7v/q7Yc8QRR3TW99lnn+IaDz74YN8zMVht2zYzPUO/7DkkydKlSzvrixcvHsh1li1b1lk/8MADi2v8+Mc/HsgsNRmVPcd+81+VzrhJku9///ud9cc//vEDmWX16tWd9X5eV2yxxRYDmWUYDjjggGLPN77xjSFMMlrWt9+4gwMAAFRDwAEAAKoh4AAAANUQcAAAgGoIOAAAQDUEHAAAoBoCDgAAUA0BBwAAqMamMz0A02eXXXYp9vzZn/1Zsefss8/urDvEE+hXP4dnHnrooUOYJLngggs66w7xZGPzy1/+stjzspe9rLP+iU98orjGvHnzij1z5szprA/rEM+vfe1rxZ7ly5cXe4466qjO+vHHH19cw0Gf/XMHBwAAqIaAAwAAVEPAAQAAqiHgAAAA1RBwAACAagg4AABANQQcAACgGgIOAABQDQd9Vqx0qFSSbL755sWeSy+9dBDjAOTVr351saefQwBLmqYp9vzbv/3blK8DG5srrriis37EEUcU1/jd3/3dYs/pp5/eWV+zZk1xjbe85S3FntJBnqXHmySPecxjij033HBDZ/3YY48trtHP4eyMcwcHAACohoADAABUQ8ABAACqIeAAAADVEHAAAIBqCDgAAEA1BBwAAKAazsEZYY997GM76yeddFJxjauuuqrY86Mf/ajvmQC67LLLLkO5zr333lvsWbZs2RAmgY1L6VyZJNl5552Hcp0zzjhjytfpxy9+8Ytiz4oVKzrr22+/fXGN3XbbrbN+4403FtfYWLiDAwAAVEPAAQAAqiHgAAAA1RBwAACAagg4AABANQQcAACgGgIOAABQDQEHAACohoM+R9gzn/nMzvqCBQuKa7zoRS8q9tx11139jgRsxJ71rGcVewZxwF8/7rzzzmLPV77ylSFMAhuXuXPnFnsuuOCCYs/PfvazzvqJJ57Y70izwne/+93O+k477VRcY7/99uusO+jz/3MHBwAAqIaAAwAAVEPAAQAAqiHgAAAA1RBwAACAagg4AABANQQcAACgGgIOAABQDQd9jrCTTz65s/6LX/yiuMZ11103oGmA2m2//fad9XPOOae4xuabbz6ocTqde+65Q7kO8J/9wR/8wUDWOe644zrr3/ve9wZynWE55ZRTOuvPfe5zi2scdNBBnfV/+Id/2KCZauYODgAAUA0BBwAAqIaAAwAAVEPAAQAAqiHgAAAA1RBwAACAagg4AABANZyDM0vtuOOOxZ799tuvs/7Vr361uMbKlSv7ngnYuO20006d9YULFw5ljssvv7zY87d/+7dDmARY15IlS4o9P/rRj4o9V1111SDGmTUe85jHdNabpimusWjRokGNUz13cAAAgGoIOAAAQDUEHAAAoBoCDgAAUA0BBwAAqIaAAwAAVEPAAQAAqiHgAAAA1XDQ5yxVOsQzSe6///7O+hvf+MZBjQOQww8/fCjXueeeezrrZ555ZnGNNWvWDGgaYEPMnz+/2LPZZpsVezbffPPOeuk10GyzYMGCzvomm5TvOdx2222DGqd67uAAAADVEHAAAIBqCDgAAEA1BBwAAKAaAg4AAFANAQcAAKiGgAMAAFTDOTgzYOutty72nHPOOcWe17/+9Z31L37xi33PBGzc9t1332LPS1/60iFMkpx//vmd9auvvnoocwAb7ilPeUqxZ6uttir2XHjhhZ31k08+ubjGLbfcUuwZlpNOOmnKa3hd1z93cAAAgGoIOAAAQDUEHAAAoBoCDgAAUA0BBwAAqIaAAwAAVEPAAQAAqiHgAAAA1Wjatl1/sWnWX+Rh6+ewp34OsNpll10662vWrOl3JCrWtm0z0zP0y54zPebOnVvs+dSnPlXsOfzwwwcxTtEBBxzQWf/GN74xlDl4eEZlz7HfTI83vvGNxZ7TTz99ytfpev261hVXXFHs+dKXvtRZP+GEE4prbLfddsWeOXPmdNbvueee4ho77bRTZ3358uXFNWqzvv3GHRwAAKAaAg4AAFANAQcAAKiGgAMAAFRDwAEAAKoh4AAAANUQcAAAgGoIOAAAQDU2nekBavT0pz+9s/6Sl7ykuMYLXvCCYo+DPIF+LFq0qNgzrEM8zz777GLPt7/97SFMAkyHd7zjHcWeI488stjzlKc8pbM+b9684hq/93u/N+Wefg4U7UfTdJ9/e9ZZZxXX2BgP8ny43MEBAACqIeAAAADVEHAAAIBqCDgAAEA1BBwAAKAaAg4AAFANAQcAAKhG0/X53k3TDObDv4EZ07Zt94fvzyL2nOnRz9kzJ5988pSv85Of/KTY84xnPKPYc+utt055FmbOqOw59pvZ7clPfnJnfcmSJcU19t1332LP7rvv3lm/++67i2vccsstxZ7S+UBXXnllcY1BnclTk/XtN+7gAAAA1RBwAACAagg4AABANQQcAACgGgIOAABQDQEHAACohoADAABUQ8ABAACq4aBPqNyoHLqX2HOmSz8H4l188cXFnmXLlnXWDzvssOIaN9xwQ7GH0TYqe479Bkafgz4BAIDqCTgAAEA1BBwAAKAaAg4AAFANAQcAAKiGgAMAAFRDwAEAAKoh4AAAANVw0CdUblQO3UvsOVCDUdlz7Dcw+hz0CQAAVE/AAQAAqiHgAAAA1RBwAACAagg4AABANQQcAACgGgIOAABQDQEHAACohoADAABUQ8ABAACqIeAAAADVEHAAAIBqCDgAAEA1BBwAAKAaAg4AAFANAQcAAKhG07btTM8AAAAwEO7gAAAA1RBwAACAagg4AABANQQcAACgGgIOAABQDQEHAACoxv8DsmtGnjJXl5cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x576 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_predictions(model, test_loader, device, n_samples=6):\n",
    "    \"\"\"\n",
    "    Plot random test images with their predictions and actual labels\n",
    "    \"\"\"\n",
    "    # Get a random batch\n",
    "    test_features, test_labels = next(iter(test_loader))\n",
    "    \n",
    "    # Get random indices\n",
    "    rand_idx = torch.randint(0, len(test_features), (n_samples,))\n",
    "    \n",
    "    # Get samples\n",
    "    samples = test_features[rand_idx].to(device)\n",
    "    labels = test_labels[rand_idx]\n",
    "    \n",
    "    # Get predictions\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        logits = model(samples)\n",
    "        predictions = torch.softmax(logits, dim=1)\n",
    "        pred_labels = torch.argmax(predictions, dim=1)\n",
    "    \n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx in range(n_samples):\n",
    "        # Plot image\n",
    "        axes[idx].imshow(samples[idx].cpu().squeeze(), cmap='gray')\n",
    "        \n",
    "        # Add title with prediction and actual\n",
    "        title = f'Pred: {pred_labels[idx].item()}\\nTrue: {labels[idx].item()}'\n",
    "        axes[idx].set_title(title, color='green' if pred_labels[idx] == labels[idx] else 'red')\n",
    "        \n",
    "        # Remove axes\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage:\n",
    "plot_predictions(model_0, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75a6447-da22-40b7-81ef-b58773e6dd44",
   "metadata": {},
   "source": [
    "Above are some sample predictions from our model. Green titles indicate correct predictions, while red shows where the model made mistakes. It's fascinating to see which digits the model finds tricky - sometimes they're the same ones humans might struggle with!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c76d446-b375-4221-a945-f7ab6d32276b",
   "metadata": {},
   "source": [
    "## Key Learnings\n",
    "\n",
    "1. **Simple Can Be Powerful**: With just three layers and 25 neurons each, we achieved 95% accuracy. This shows that complex problems don't always need complex solutions.\n",
    "\n",
    "2. **Consistent Performance**: Our model maintained steady accuracy across epochs, suggesting stable learning.\n",
    "\n",
    "3. **Quick Training**: The entire training process took about 5 minutes on an RTX 2080, making it practical for experimentation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78c844d-f327-49c2-a1c0-30df28888e03",
   "metadata": {},
   "source": [
    "## What's Next?\n",
    "\n",
    "While 95% accuracy is impressive, there's always room for improvement. Here are some possible enhancements:\n",
    "\n",
    "1. Try Convolutional Neural Networks (CNNs)\n",
    "2. Experiment with different architectures\n",
    "3. Add data augmentation\n",
    "4. Implement dropout for better generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c36ad80-c909-43b2-853c-267ce1dfb27e",
   "metadata": {},
   "source": [
    "## Conclusion: What We Learned\n",
    "\n",
    "Building this digit classifier taught us some valuable lessons:\n",
    "\n",
    "- Simple architectures can be surprisingly effective\n",
    "- The importance of choosing the right hyperparameters\n",
    "- How different components (loss, optimizer, architecture) work together"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
